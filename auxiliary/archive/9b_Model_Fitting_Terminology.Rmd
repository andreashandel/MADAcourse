---
title: MADA Fall 2019 - Model Fitting Terminology
subtitle: ""
author: Andreas Handel
institute: "University of Georgia"
date: "`r file.mtime(knitr::current_input())`"
output: 
  html_document:
    toc_depth: 3
---

```{r, include=FALSE}
#just so I can use emoticons
#devtools::install_github("hadley/emo")
library(emo)
#set some figure options
knitr::opts_chunk$set(out.width = '70%')
```

# Overview

The broad field of data analysis has, in recent years, seen a lot of progress and changes. Long the domain of Statistics, in past years, other fields such as Computer Science, Engineering, and Business have all started to contribute toward the overall progress in data analytics. With a lot of old and new players engaged in this topic, a lot of new terminologies have emerged. Some of this terminology can be quite confusing, especially if different terms are used for the same concept. Throughout this course, I try to mention alternative names for any concept whenever I introduce it. The following is a brief discussion of the main names given to the task of analyzing data.

One of the hot - and also confusing - terms in recent years is __Machine Learning__ (and the related terms of __Data Mining__, __Deep Learning__, and __Artificial Intelligence__), and how they relate to __Statistics__. There is a lot of debate about what exactly those different areas are. If you are interested in some of that, check out for instance [this blog post by Frank Harrell](https://www.fharrell.com/post/stat-ml/) - as well as the references at the end of the post. While making those distinctions can be at times useful, the reality is that the terminology is not clearly defined and all over the place. From a practical/my point of view, it is, not worth spending much time trying to come up with a clear definition. So here are my - arguably fuzzy, but hopefully still somewhat useful - thoughts on how to distinguish those topics. 



# Statistics and Machine Learning

__Statistics__ is the classical machinery driving data analysis. Depending on the type of data, many different approaches have been developed (parametric vs. non-parametric methods, longitudinal analysis, time-series analysis, and many more). Models are in general simple and interpretable, and the goal is to understand how inputs (predictors) relate to outcomes. Statistics was developed when data was sparse, computers didn't exist, and mainly scientists interested in a deep understanding of their data used it. Because of this, statistical models tend to be simple and work well on small datasets.

In __Machine Learning__, the models tend to be more complex, and the goal is mainly on getting a "powerful" model, i.e., a model that is good at prediction. Understanding how different inputs lead to different outcomes is of secondary importance. Data is often abundant, so more complex models can be used. 

Thus, a fairly simple model like a linear model or a classification tree could be considered statistical models, while a more complex support vector machine or random forest (a combination of trees) could be considered machine learning models. However, the terminology is poorly-defined, and you will see pretty much any approach can be given any label. Often it makes sense to think of the two terms as describing more or less the same thing, and that is applying some kind of mathematical or computational model to gain insight from the data. For some similar ideas, and a bit more details, [read this blog post](https://www.sharpsightlabs.com/blog/difference-machine-learning-statistics-data-mining/).


# Related Terms

The term __Data Mining__ is often used interchangeably with __Machine Learning__. It might sometimes indicate a "fishing" approach of combing through data to look for patterns, without pre-defined hypotheses to be tested. As such, results from __Data Mining__ explorations need to be confirmed with independent data. __Exploratory Data Analysis__ or __Secondary Data Analysis__ mean pretty much the same thing, though the latter are often done using smaller (Statistics) as opposed to larger (Machine Learning) models. Terminology and use of the words is fuzzy.

The term _Deep Learning_ is generally used when one class of machine learning models, namely neural nets, are applied to a data analysis problem. The "deep" part comes from the fact that the neural net models generally have multiple layers stacked on top of it (it has nothing to do with deep as in especially insightful).

The use of deep learning and related approaches applied to "complex" problems is often labeled __Artificial Intelligence__. 

Neural nets (and similar complex methods) usually need a lot of data to perform well. Thus, the term __Big Data__ often shows up together with these other terms. 

In general, there is currently a lot of hype around these topics, and people - especially in the business, but also the research community - use the words __Deep Learning__ and __Artificial Intelligence__ quite liberally, even if all they do is fit a linear model to data. 

We'll discuss these topics a bit more at the end of the course, but since most scientific inquiry focuses on understanding patterns (i.e., questions tend to be inferential/causal/mechanistic) and amounts of data - while growing - still tend to be on the small side. So we won't spend much time on it.
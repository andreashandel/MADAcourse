{
  "hash": "1b7a611cef974da89d9c2a2853491fbb",
  "result": {
    "markdown": "---\ntitle: Open Science and Reproducible Research\nsubtitle: \"\"\nauthors: [Zane Billings, Andreas Handel]\n---\n\n\n\n# Overview\n\nIn this unit, we'll talk a bit more about reproducible research, and how that fits into the much larger concept of \"open science.\"\n\n\n\n# Learning Objectives\n\n* Understand the general idea of open science\n* Explain what makes research reproducible and/or replicable\n* Know what FAIR data standards are\n\n# Introduction\n\nWay back at [the beginning of the course](../intro_tools/Tools_Reproducibility.qmd),\nwe briefly discussed reproducibility. Throughout the course, we emphasized the importance to do analyses in a reproducible (and thus generally automated/scripted) manner. In this module, we'll discuss a bit more what reproducible research means and entails, current trends towards open science, and why you pretty much need to have a solid grasp on reproducible research strategies in the future. \n\n\n# Federal open science requirements\n\nWhile the concepts of reproducible research and open science have been around for a while, they have recently increased in prominence.\nSeveral US government organizations have said that [2023 is the Year of Open Science](https://www.earthdata.nasa.gov/news/year-of-open-science), and a recent\nOffice of Science and Technology Policy [memo](https://www.whitehouse.gov/ostp/news-updates/2022/08/25/ostp-issues-guidance-to-make-federally-funded-research-freely-available-without-delay/) has recommended that all federal agencies take serious steps towards open science practices (more on what exactly\nthis means later).\n\nFederal agencies like the NIH have been requiring data sharing and public\nreleases of papers (on PMC) for some time now, but these recommended measures\nare even stronger, and in my opinion, a very positive direction for science.\nIt is quite likely that if you work with federal funding in the near future,\nyou will be required to share your data and code publicly as soon as you\ndecide to publish. The exact implementation of these protocols hasn't been\ndetermined yet (nor has the degree to which these recommendations will be\nformally implemented), but the writing is on the wall, so to speak.\n\n**It is easier for you to get comfortable with reproducible research methods\nand open science now, rather than scrambling to learn it in the future!**\n\n# The general idea of open science\n\nThere are many ways of defining and describing \"open science\".\n\nIf you search online for \"what is open science,\" you will likely find various conceptual diagrams and descriptions. The papers [Open science saves lives: lessons from the COVID-19 pandemic](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01304-y) \nand [From Open Data to Open Science](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020EA001562)\nprovide pretty good conceptual discussions of open science, but I think the\nbest of schematic summary is from [NASA](https://www.earthdata.nasa.gov/esds/open-science/oss-for-eso-workshops).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](../../media/open-science.jpg){fig-align='center' fig-alt='A circular graphic with \\'open science\\' in the center, showing several components of open science around it ([source](https://www.earthdata.nasa.gov/esds/open-science/oss-for-eso-workshops)).' width=50%}\n:::\n:::\n\n\nNASA defines three components that are central to open science.\n\n1. Accessible -- your research process and results need to be transparent. Open access,\nFAIR data, and code sharing all fall into this.\n2. Reproducible -- other people should be able to get the same results as you,\nand you should strive to make reusable products.\n3. Inclusive -- if your research is only accessible and reproducible for\nrelatively well-off scientists at major institutions in the USA, it's still\nnot really open üôÇ.\n\nIf you want a formal definition of \"open science,\" here's the one from the\nOSTP, which is pretty comprehensive:\n\n> ‚ÄúThe principle and practice of making research\nproducts and processes available to all, while\nrespecting diverse cultures, maintaining security\nand privacy, and fostering collaborations,\nreproducibility, and equity.‚Äù\n\nOpen science is like spaghetti sauce--it has a lot of ingredients that have to be cooked together to get the best flavor. \nLet's go into a bit more detail on each of these topics.\n\n# Accessibility and FAIR data\n\nOpen access publishing is a big topic, but for the purposes of this class\nI will just say that I think you should publish Open Access whenever possible.\nWhile you're a student at UGA, [our library has a fund](https://www.libs.uga.edu/openaccessfund)\nthat can help you with this. In the future, it seems likely that any federally\nfunded projects in the US will require an open access fund as part of the budget,\nas publishing OA can often be prohibitively expensive. If you want to learn\nmore check out [wikipedia page](https://en.wikipedia.org/wiki/Open_access),\nor if you *really* want to learn more, see [Peter Suber's book on OA](https://dash.harvard.edu/bitstream/handle/1/10752204/9780262517638_Open_Access.pdf).\n\nThe main purpose of this section is to talk about data sharing. Data sharing\nused to be a pretty contentious topic, but fortunately it is more normalized\nnow than it has ever been before, and thanks to NIH (and other agency mandates),\nit will likely be a normal part of science before too long.\n\nOf course just dumping messy data without any documentation into a depository is not great\nfor accessibility and reproducibility. As some of you noticed during this\ncourse, even data from the CDC or other reputable organizations is often\nvery poorly formatted and does not have a lot of metadata or documentation\nto help you out. To somewhat solve this issue, the FAIR data\nstandards was created. FAIR stands for:\n\n1. **F**indable: when someone goes to your paper or project, they should be\nable to easily get to the data source.\n2. **A**ccessible: users need to be able to access the data, and data are stored\nin a way that users can feasibly get them.\n3. **I**nteroperable: data should be in standardized formats, using standard\nvocabulary. You should be specific if your data is derived from another dataset\nor if the user will need other related datasets.\n4. **R**eusable: data should be documented and version-controlled when you\nrelease it, with clear descriptions of what information is contained in the\ndata, who can use the data, and for what purposes.\n\n\nThe FAIR standard was originally described in [this 2016 publication](https://www.nature.com/articles/sdata201618).\nAnother great resource is the [GO FAIR initative](https://www.go-fair.org/fair-principles/). It is worth taking a short look at both these resources.\n\nOf course dealing with things like data use agreements and individual privacy\nis paramount, so 100% achieving these goals all the time is not feasible.\nSometimes you might need to use [synthetic data](https://en.wikipedia.org/wiki/Synthetic_data)\nbased on your real data, or remove certain information from your data to protect\nprivacy, or require a data use agreement before you can distribute the\ndata to individuals. We should strive for data to be as FAIR as possible,\nbut protecting individual privacy is equally important!\n\nIn general, a lot of authors still hide behind \"I can't share my data, it's confidential\" as an excuse for not having to share. Most of the time, it is possible to share de-identified data without confidentiality problems. Hopefully, the near future will make data sharing much more common and also easier.\n\n\n# Reproducibility (and replicability too)\n\nWe discussed **reproducibility** in [this reading](../intro_tools/Tools_Reproducibility.qmd), revisit it if you need a refresher.\nIn one sentence, *your research is reproducible if another scientist can repeat your methods on your data and get the same results.* That is, someone\nelse can take your code and data, rerun all your code, and get the same answers that you got in your paper.\n\nAn important and related issue is **replicability** -‚Äî you've probably heard of\nthe \"replication crisis\" in science. If not, see for instance this [wikipedia page](https://en.wikipedia.org/wiki/Replication_crisis). \nIn one sentence, *your research is replicable if someone else can follow your methods and materials to collect new data, analyze their data, and get similar results*. \nOf course in social and semi-social sciences (like epidemiology), when your results often\ndepend on the target population of interest and are expected to vary over\ntime, replicability can be a bit more nuanced than in an experimental\nfield, where experiments should pretty much control for anything that you\naren't interested in.\n\nNote that replicability is somewhat related to the analysis topic of generalizability/portability we discussed. The difference is that we focused on analysis approaches that would lead to replicable modeling/analysis results using other data sources. More broadly, one wants to be able to replicate overall findings if one were to repeat the full study, including collection of new data. This is important, but for purposes of analysis, the data is considered given, and the focus is on reproducibility/replicability of the data analysis part.\n\n\n\n# Inclusivity\n\nThe topic of inclusivity in data science is heavily tied into the idea of\ndata ethics -- critical thinking about the potential results and consequences\nof the products we create is crucial in data science. Many of you have some public health training, and are therefore likely familiar with [the Belmont Report](https://www.hhs.gov/ohrp/regulations-and-policy/belmont-report/index.html).\nRegardless of your scientific background, when working with data (especially\nhuman subjects data), the guiding principles of respect for persons, beneficience, and justice\nshould be critical considerations for all of our research.\n\nFor some additional reading on inclusivity and data science ethics, see for instance these resources:\n\n* Elaine O Nsoesie, Sandro Galea, Towards better Data Science to address racial bias and health equity, PNAS Nexus, Volume 1, Issue 3, July 2022, pgac120, https://doi.org/10.1093/pnasnexus/pgac120\n* O'Neil, Cathy. Weapons of math destruction. Crown, 2016. ISBN: 978-0553418811.\n* Noble, Safiya Umoja. Algorithms of Oppression: How Search Engines Reinforce Racism. NYU Press, 2018. ISBN: 978-1479837243.\n* [https://datapractices.org/manifesto/](https://datapractices.org/manifesto/)\n* Floridi L, Taddeo M. What is data ethics?. Philos Trans A Math Phys Eng Sci. 2016;374(2083):20160360. doi:10.1098/rsta.2016.0360\n\n\n# Practical considerations\n\nIt is all nice and good to tell people that their data needs to be FAIR, and that their science needs to be open. But the question is, why do it? Most people might agree that there are societal benefits. For instance having a resource like GenBank for genetic sequences has allowed many scientists beyond those who created the original sequence to use the data and answer important scientific questions. However, there generally need to also be benefits for individuals to entice them to spend time following Open Science standards. This is happening increasingly. On one hand, tools to do research in an Open Science framework are getting increasingly better. For instance the whole `R` + `Quarto` framework we've been using in class makes it rather easy to do things automated and reproducible. Many other similar tools and resources are becoming available. Another potential benefit of Open Science is increased visibility. If others can use your data and models, they will likely cite your work. They might even want to collaborate with you. It seems for those individuals who are good at sharing, the benefits outweigh the perceived risks (such as \"being scooped\"). And the final, ever increasing \"benefit\" is that publishers and funding agencies increasingly require it. So if you don't follow Open Science standards, it might soon get hard to publish work or get funding. It's less of a \"benefit\" and more of an \"avoid the penalties\" thing, but regardless, it is an important practical consideration. \n\n\n# Further reading\n\nEverything we discussed throughout this course, and this short introduction, hopefully conveyed the message that Open Science is an important topic to think about and strive toward. \nThe importance of the topic has been increasing in recent years. It is useful to stay somewhat informed. Here are a few places you can find more open science resources.\n\n* The Center for Open Science, a nonprofit dedicated to promoting open science\npractices and community change, maintains [a blog](https://www.cos.io/blog)\nwith several thought provoking readings.\n* Statistician Andrew Gelman sometimes writes about open science, mostly from\na statistical perspective and has some nice comments on replication.\n[(1)](http://www.stat.columbia.edu/~gelman/research/published/ChanceEthics14.pdf)\n[(2)](https://www.americanscientist.org/article/the-statistical-crisis-in-science)\n* [FOSTER](https://www.fosteropenscience.eu/) is a European organization\nwith a set of free courses on open science principles.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
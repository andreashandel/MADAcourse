<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Andreas Handel" />


<title>Subset Selection</title>

<script src="site_libs/header-attrs-2.20/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<link href="site_libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
<script src="site_libs/bs3compat-0.4.2/transition.js"></script>
<script src="site_libs/bs3compat-0.4.2/tabs.js"></script>
<script src="site_libs/bs3compat-0.4.2/bs3compat.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link rel="icon" type="image/png" href="media/MADAlogo.png" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MADA Course</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    General Information
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="./Course_Syllabus.html">Syllabus</a>
    </li>
    <li>
      <a href="./Course_Schedule.html">Schedule</a>
    </li>
    <li>
      <a href="./Course_Communication.html">Communication</a>
    </li>
    <li>
      <a href="./Course_Assessments.html">Assessments</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Modules
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">1. Course and Tools Introduction</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Introduction_Course.html">Course Introduction</a>
        </li>
        <li>
          <a href="./Tools_RandRStudio.html">R and Rstudio</a>
        </li>
        <li>
          <a href="./Tools_Github_Introduction.html">GitHub Introduction</a>
        </li>
        <li>
          <a href="./Tools_Github_R_Workflow.html">GitHub and R Workflow</a>
        </li>
        <li>
          <a href="./Tools_Reproducibility.html">Reproducibility, Quarto &amp; Co</a>
        </li>
        <li>
          <a href="./Tools_Reference_Management.html">Reference Management</a>
        </li>
        <li>
          <a href="./Assessment_Course_Tools_Introduction.html">Assessment: Course and Tools Introduction</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">2. Data Analysis Introduction</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Data_Analysis_Motivation.html">Motivating Examples</a>
        </li>
        <li>
          <a href="./Data_Analysis_Overview.html">Data Analysis Overview</a>
        </li>
        <li>
          <a href="./Data_Analysis_Structure.html">Data Analysis Structure</a>
        </li>
        <li>
          <a href="./Assessment_Data_Analysis.html">Assessment: Data Analysis Introduction</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">3. R Coding Basics</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Rcoding_Basics.html">R Coding Basics</a>
        </li>
        <li>
          <a href="./Rcoding_Tidyverse.html">Tidyverse and Friends</a>
        </li>
        <li>
          <a href="./Assessment_Coding.html">Assessment: R Coding Basics</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">4. Contemplating, finding and wrangling data</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Data_Types.html">Data Types</a>
        </li>
        <li>
          <a href="./Data_Finding.html">Finding Data</a>
        </li>
        <li>
          <a href="./Data_Wrangling.html">Data wrangling</a>
        </li>
        <li>
          <a href="./Assessment_Data_Finding_Wrangling.html">Assessment: Data Finding and Wrangling</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">5. Visualization</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Visualization_Overview.html">Visualization Overview</a>
        </li>
        <li>
          <a href="./Visualization_in_R.html">Visualization in R</a>
        </li>
        <li>
          <a href="./Assessment_Visualization.html">Assessment: Visualization</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">6. Data Exploration</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Data_Exploration.html">Exploring data</a>
        </li>
        <li>
          <a href="./Assessment_Exploration.html">Assessment: Exploration</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">7. Statistical analysis overview</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Statistical_Analysis_Introduction.html">Statistical analysis introduction</a>
        </li>
        <li>
          <a href="./Statistical_Terminology.html">Some Statistical Model Fitting Terminology</a>
        </li>
        <li>
          <a href="./Assessment_Statistical_Analysis.html">Assessment: Statistical Analysis Overview</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">8. Fitting basic statistical models</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Basic_Statistical_Models.html">Basic statistical models</a>
        </li>
        <li>
          <a href="./Model_Fitting_R.html">Fitting statistical models in R</a>
        </li>
        <li>
          <a href="./Assessment_Fitting_Basic_Models.html">Assessment: Fitting Basic Models</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">9. Evaluating your model fits</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Model_Evaluation_Overview.html">Model evaluation overview</a>
        </li>
        <li>
          <a href="./Model_Evaluation_Performance.html">Model performance evaluation</a>
        </li>
        <li>
          <a href="./Model_Evaluation_Overfitting.html">Model performance &amp; overfitting</a>
        </li>
        <li>
          <a href="./Model_Evaluation_Diagnostics.html">Model Diagostics</a>
        </li>
        <li>
          <a href="./Model_Evaluation_Uncertainty.html">Model Uncertainty</a>
        </li>
        <li>
          <a href="./Assessment_Model_Evaluation.html">Assessment: Model evaluation</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">10. Improving your model fits</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Model_Improvement_Overview.html">Improving model fits overview</a>
        </li>
        <li>
          <a href="./Model_Improvement_Data_Processing.html">Pre-processing data</a>
        </li>
        <li>
          <a href="./Model_Improvement_Subset_Selection.html">Subset selection</a>
        </li>
        <li>
          <a href="./Model_Improvement_Regularization.html">Regularization</a>
        </li>
        <li>
          <a href="./Model_Improvement_Tuning.html">Model tuning</a>
        </li>
        <li>
          <a href="./Assessment_Model_Improvement.html">Assessment: Model Improvement</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">11. Machine Learning Models I</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./ML_Models_Overview.html">ML Models overview</a>
        </li>
        <li>
          <a href="./Polynomial_Spline_Models.html">Polynomial and Spline Models</a>
        </li>
        <li>
          <a href="./Decision_Trees.html">Decision Trees</a>
        </li>
        <li>
          <a href="./Many_Tree_Models.html">Many-tree models</a>
        </li>
        <li>
          <a href="./Assessment_ML_Models_1.html">Assessment: ML models 1</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">12. Machine Learning Models II</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./SVM_Models.html">Support Vector Machine Models</a>
        </li>
        <li>
          <a href="./DA_Models.html">Discriminant Analysis Models</a>
        </li>
        <li>
          <a href="./More_ML_Models.html">Some more ML models</a>
        </li>
        <li>
          <a href="./Assessment_ML_Models_2.html">Assessment: ML models 2</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">13. The complete analysis workflow</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./Complete_data_analysis_workflow.html">Complete data analysis workflow</a>
        </li>
        <li>
          <a href="./Data_Models_Not_Covered.html">More Data and Models</a>
        </li>
        <li>
          <a href="./Open_Science.html">Open Science</a>
        </li>
        <li>
          <a href="./Assessment_Complete_Workflow.html">Assessment: Complete Analysis Workflow</a>
        </li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">14. Deep learning, AI and Big data</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="./DL_AI_BigData.html">Deep Learning, AI and Big Data</a>
        </li>
      </ul>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Project
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="./Project_Overview.html">Project Overview</a>
    </li>
    <li>
      <a href="./Project_Details.html">Project Details</a>
    </li>
    <li>
      <a href="./Project_Review.html">Project Review</a>
    </li>
    <li>
      <a href="./Project_Examples.html">Project Examples</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="./Course_Resources.html">Course Resources</a>
    </li>
    <li>
      <a href="./General_Resources.html">General Resources</a>
    </li>
    <li>
      <a href="./Course_Glossary.html">Glossary</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/andreashandel/MADAcourse">
    <span class="fab fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Subset Selection</h1>
<h4 class="author">Andreas Handel</h4>
<h4 class="date">2023-03-28 12:42:29</h4>

</div>


<div id="overview" class="section level1">
<h1>Overview</h1>
<p>In this unit, we will cover the idea of subset selection.</p>
</div>
<div id="learning-objectives" class="section level1">
<h1>Learning Objectives</h1>
<ul>
<li>Know what subset selection is and when to use it.</li>
</ul>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In our previous discussion of model performance, you were introduced
to the problem of <strong>overfitting.</strong> Here is a quick repeat.
The idea is that you generally want to make inferences or predictions
<strong>not for the data you used to fit your model, but for
new/different data.</strong></p>
<p>If the goal was to fit the data you have as well as possible, you
could always achieve that with a complex model. If you have N
observations, you can find a polynomial of degree N-1 that hits all of
your data points. However, as discussed when we talked about the
<strong>bias-variance trade-off</strong>, a model that gets too close to
the data used for fitting will generally not perform well when applied
to new data.</p>
<p>You want a model that gets the trade-off between high bias (model not
flexible enough to capture all the patterns seen in the data) and high
variance (model too flexible, will capture noise as well) right.</p>
<p>I showed the figure below previously. I’m repeating it here as a
refresher. The yellow model (straight line), in this example, has too
much bias. The model is too simple to capture all the important
patterns, and it <strong>underfits</strong> the data. The performance
metric (mean square error here) is high for both the training and
test/CV data (yellow squares on the left of the right panel.) The green
model (very wiggly line) has too much variance. It goes too close to the
data used for fitting and doesn’t generalize to new data, it
<strong>overfits</strong> the data. This reflects itself in good
performance (low MSE) for the train data, but high MSE for the test/CV
data (green squares on left of the left panel) In this example, the blue
model has the optimal model complexity. It captures the overall pattern
in the data, without trying to fit the noise/variability. This manifests
itself with the best performance on the test/CV data (blue squares).</p>
<div class="figure" style="text-align: center">
<img src="media/islr-fig29.jpg" alt="A scatterplot with two panels. The left panel shows several data points along with a few different models: a straight line, a curve that passes through the middle of the points, and a curve that oscillates frequently to hit many of the points. The right panel shows the MSE of these models against the training data, where the oscillating curve performs best, and also against new data, where the curve which oscillates less frequently performs best." width="769" />
<p class="caption">
Bias-variance tradeoff. Source: ISLR.
</p>
</div>
<p>We talked about cross-validation and how it can be used to help you
determine if your model overfits (or underfits). What we haven’t
discussed is how to find a model that gets the trade-off between bias
and variance right. Two common techniques are subset selection and
regularization.</p>
<p>The general idea for these strategies is that if you let the model
use all the predictors you have (this is called a <em>full</em> or
sometimes <em>saturated</em> model), it might be too big and overfit the
data. You can get some hint of that if the cross-validated performance
measure for a full model is not better than that for a null model or a
single-predictor model. The latter ones are likely too simple and
underfit (unless none or a single predictor describes your data), while
the full model is likely too flexible and overfits. So you want to find
a model that only uses the important/useful predictors.</p>
</div>
<div id="subset-selection" class="section level1">
<h1>Subset selection</h1>
<p>You might have already seen subset selection in another statistics
class. If that is the case, this is a refresher. Though you might not
have used the approaches I describe here to perform subset selection.
Subset selection is also called <em>variable selection</em> or
<em>feature selection</em>. The overall idea is that you try models with
different numbers of predictors included/excluded, you evaluate its
performance (using cross-validation to get an honest estimate of model
performance on new data), and pick the reduced/sub-model with the best
performance. The performance is measured using whatever metric you
decided to optimize on (SSR, RMSE, Accuracy, F1 score, etc.). There are
different ways you can go about trying different sub-models, as
described in the following sections.</p>
<div id="forward-selection" class="section level2">
<h2>Forward selection</h2>
<p>In forward selection, you start with the null-model (no predictors),
then evaluate all single-predictor models. The best-performing
1-predictor model is chosen, and you build all 2-predictor models on top
of that chosen 1-predictor model. You choose the best 2-predictor model,
then go on to add a third, and do that until adding any further
predictors does not lead to a model that performs better (<strong>again,
measured by CV on the test set</strong>) than the smaller model. E.g.,
you might find that adding any of the remaining 3rd predictors does not
lead to a better-performing model than the 2-predictor model you already
have. Then you stop here and pick the 2-predictor model as your
best.</p>
<p>Let’s consider an example. Say you want to predict <code>BMI</code>
based on <code>age</code>, <code>sex</code>,
<code>calorie intake</code>, and <code>exercise level</code>. Since BMI
is continuous, we can consider a linear regression model, and we might
try to minimize RMSE between model-predicted BMI and actual
measurements. We start by computing RMSE for the null model. Then we
compute RMSE for all 1-predictor models. Assume that all 1-predictor
models have RMSE lower than the null model, and the lowest RMSE (all
computed using cross-validation) of the 1-predictor models is the one
that includes <code>calorie intake</code>. Next, you try all 2-predictor
models that include <code>calorie intake</code>. Among those, a model
with <code>calorie intake + exercise level</code> has the lowest RMSE,
and it’s also lower than the model with <code>calorie intake</code>
only. Next, you try all 3-predictor models that include the 2 chosen
predictors. In this example, only 2 of those 3-predictor models are
possible, namely <code>calorie intake + exercise level + age</code> and
<code>calorie intake + exercise level + sex</code>. Let’s assume both of
those models have RMSE that is larger than the 2 predictor model. Note,
it is important to compute RMSE through cross-validation since the RMSE
evaluated on the data used for fitting will always be lower for the
bigger model. We thus found our best model, namely one that includes the
2 predictors <code>calorie intake + exercise level</code>.</p>
</div>
<div id="backward-selection" class="section level2">
<h2>Backward selection</h2>
<p>Backward selection is essentially the reverse to forward selection:
You start with the model with all predictors, then evaluate all models
with one predictor dropped. The smaller model with the best performance
is your choice. You then drop each predictor at a time from that model.
You continue until dropping predictors does not improve performance
anymore. Then you keep the model with the best performance. Note that
this method does not work on datasets that have more predictors than
observations (e.g., most -omics type data).</p>
<p>Let’s consider the above example again. We now start with a model
that includes all 4 predictors and compute cross-validated RMSE. Next,
we drop each predictor and try all 3-predictor models. Let’s say the one
that dropped <code>exercise level</code> is the 3-predictor model with
the lowest RMSE, lower than all other 3-predictor models, and lower than
the full model. Next, we drop each variable from the current best
candidate 3-predictor model, which is
<code>age + sex + calorie intake</code>. All of the 2-predictor models
have RMSE larger than the 3-predictor model. We thus found our final
model, with the 3 predictors
<code>age + sex + calorie intake</code>.</p>
<p>Note that it is also possible to do “forward-backward” selection: you
can choose to start with the full or reduced model, but the method is
allowed to add/remove predictors at every step depending on what
improves performance most.</p>
</div>
<div id="exhaustive-subset-selection" class="section level2">
<h2>Exhaustive subset selection</h2>
<p>You might have noticed that in my example, forward selection and
backward selection do not necessarily produce the same model. The reason
for that is that neither forward- or backward-selection try all possible
models (predictor combinations). Both approaches use what is called a
<em>greedy</em> strategy. Once they included or excluded a predictor, it
can never be dropped or included. Once you picked your 1-predictor
model, all subsequent models will consist of that 1 predictor model -
even if there might be a better performing 2-predictor model that
doesn’t include the 1st predictor you picked. The same holds for
dropping predictors in backward selection.</p>
<p>Also, as in my example, often (but not always), the final model
determined through backward selection tends to include more predictors
than a model determined through forward selection. In such a case, you
have to decide which model to choose. Alternatively, you can try a
different way of choosing the model. One approach is to try models with
all combinations of predictors. This is called <em>exhaustive subset
selection</em>, <em>all subsets selection</em>, or <em>best subset
selection</em> (although note that “best subset selection” can also
refer to <a href="https://github.com/ryantibs/best-subset">a different
method</a> which still hasn’t gained much traction). If you have only a
few predictors, you can try every combination of predictors. However,
once you have more than 5-10 predictors (depending on the number of
observations), trying every combination of sub-models would be too
time-consuming. Therefore, most of the time, such an exhaustive feature
selection is not feasible.</p>
</div>
<div id="other-subset-selection-methods" class="section level2">
<h2>Other subset selection methods</h2>
<p>There have recently been a number of approaches that try to be
somewhat smarter in finding the best model, without having to try every
combination. The <code>caret</code> package has several methods, such as
Genetic Algorithms and Simulated Annealing. Those methods often do a
good job finding a very good sub-model in a reasonable amount of time.
While the only guarantee that you found the single best model is to try
them all using exhaustive subset selection, these modern approaches
usually find a model that is either the best or at least close to the
best while doing so rather efficiently. See <a
href="https://topepo.github.io/caret/">sections 18-22 of the caret
manual</a> for more information if you are interested. The
<code>mlr/mlr3</code> packages also have <a
href="https://mlr3book.mlr-org.com/optimization.html#fs">similar such
selection methods</a> (in fact, I find the <code>mlr/mlr3</code> ones
better). <code>tidymodels</code> currently does not have any subset
selection procedure implemented (see more below).</p>
</div>
<div id="manual-subset-selection" class="section level2">
<h2>Manual subset selection</h2>
<p>All the approaches above use cross-validated performance of some
metric to determine which predictors should be included in the model.
Another, still commonly used strategy is to do subset selection
manually. The analyst usually starts with a simple model containing just
one predictor (the most important one), and then decides based on model
results (e.g., systematic deviations in the residuals) and/or based on
scientific knowledge, if adding additional predictors is justified. For
a skilled analyst with a lot of subject matter expertise, this can lead
to models that are all-around very good. They have good performance,
make scientific sense, and are still simple. Unfortunately, this
requires a lot of knowledge, time and careful analysis. Also, the
analyst needs to honestly report any model they tried, not just the one
they end up with. Otherwise they are using and not reporting <a
href="https://en.wikipedia.org/wiki/Researcher_degrees_of_freedom">researcher’s
degrees of freedom</a>, which leads to overfitting. Most analyses are
not done that way.</p>
<div class="note">
<p>I mentioned this before in various places and it’s a theme throughout
the course, that unless data is collected and analyzed using
pre-specified protocols (e.g., a clinical trial for FDA approval) it is
almost always the case that scientists have so much flexibility during
the data collection and analysis stages that p-values and similar
statistical measures are meaningless. The <a
href="https://en.wikipedia.org/wiki/Researcher_degrees_of_freedom"><strong>Researcher’s
degrees of freedom</strong></a> issue is everywhere and essentially
impossible to get rid of. For more on this topic, see the “Pitfalls”
section on the <a href="./General_Resources.html">General Resources
page</a>.</p>
<p>All of this applies to manual subset selection (which is why I’m
thinking about it here and adding this note), but it is more general and
applies to every step in a scientific project.</p>
</div>
</div>
</div>
<div id="subset-selection-and-main-predictors" class="section level1">
<h1>Subset selection and main predictors</h1>
<p>Sometimes, you have predictors of particular interest, e.g., your
main exposure. What if the subset selection algorithm removes those
variables? That can happen. One reason is that the predictor/variable
you thought was important for the outcome is in fact not. Alternatively,
it could be that your main variable correlates strongly with one or a
combination of other variables, and the model routine kept those other
variables instead. Some packages in R that do subset selection allow you
to specify certain predictors that are kept, no matter what. This way
you can keep the ones you know are important, and let the computer/stats
decide if the other ones are useful or not. It is also worth thinking
about what the model is trying to tell you. If it throws out the
variable you are interested in, it means it might not be as important in
influencing the outcome as you thought. This is a situation that
requires careful thinking and judgement and then based on your best
judgment, you proceed.</p>
</div>
<div id="additional-comments" class="section level1">
<h1>Additional comments</h1>
<p>Most commonly, subset selection is used by starting with a full model
that includes each predictor/feature in linear form only. However, there
is no reason why one couldn’t build a full model that includes every
predictor in more complicated forms. For instance, one could start with
a model that includes each term linear and quadratic, e.g.</p>
<p><span class="math display">\[Y=b_0 + b_1X_1 + b_2X_1^2 + b_3 X_2 +
b_4 X_2^2 + ...\]</span></p>
<p>Interaction terms (e.g., <span class="math inline">\(X_1
X_2\)</span>) are of course also possible. One could then perform subset
selection by removing each term (though if one removes the simple term,
<span class="math inline">\(b_iX_i\)</span>, it is often a good idea to
remove the higher-order terms which include <span
class="math inline">\(X_i\)</span>, especially interaction terms). It is
rarely done, and I don’t think I’ve seen an example of this in the
literature. If interactions or higher-order terms are suspected, one
often uses a different type of machine learning model that more
naturally allows relations between predictors and outcome that are not
linear (e.g. quadratic or other complicated forms). We’ll visit some of
those models soon.</p>
<p>You might have learned other approaches to compare model performance,
e.g., using AIC or similar metrics or F-tests. As previously mentioned,
I consider cross-validation the most robust and reliable method and,
thus, do not discuss the others. AIC or similar might sometimes be
necessary if the cross-validation approach takes too long to run, e.g.,
if you have a lot of data or a complicated model. I don’t see a use for
any of the other methods. (But I’m happy to change my mind if someone
gives me some convincing reasons 😃.)</p>
<p>The subset selection methods described above can be applied to any
generalized linear model (GLM), such as linear, logistic and many
others. For subset selection to work, variables need to show up in such
a form that they can be added or removed easily. We will soon look at
machine learning models where the predictor variables are part of the
model in a complicated manner and can’t be easily added/removed in a
stepwise manner. Thus, subset selection as described here might not work
for such models. However, the similar and related term of <a
href="https://en.wikipedia.org/wiki/Feature_selection"><em>feature
selection</em></a> does apply. The term comes from ML, the idea is
similar: Try to find those features/variables that are relevant. Many of
those models have some internal mechanisms that allow the model to
decide that a certain predictor is not useful and thus remove it. We’ll
discuss that more soon.</p>
</div>
<div id="maybe-avoid-subset-selection" class="section level1">
<h1>Maybe avoid subset selection</h1>
<p>So I just explained in detail how subset selection works and what it
tries to accomplish (make simpler models and prevent overfitting), and
now I’m going to tell you to maybe avoid it 🤦?!</p>
<p>If you go to the statistical literature or online, you will find
papers and posts telling you why subset selection is bad. Here is a nice
paper that talks about it. <a href="./media/heinze17ti.pdf"><em>Five
myths about variable selection.</em></a>. Many similar papers and
discussions exist. If you want to see more, <a
href="https://en.wikipedia.org/wiki/Stepwise_regression">check
Wikipedia</a> or do a Google search on
<code>problems with stepwise selection</code>. You’ll find plenty. The
general criticism is that subset selection doesn’t solve the problem of
overfitting. Instead, by trying lots of different models, it might make
it worse. Most of the criticism is directed at doing subset selection
through AIC, F-test or other criteria, not using CV. I haven’t yet seen
a convincing article that explains that subset selection is equally bad
if one uses CV (if you find one, please let me know!) Even when using
CV, subset selection might still lead to overfitting, especially if the
amount of data you have is not large and thus CV estimates not too
reliable. Probably because of that, and also because there are other
methods, such as regularization, especially the LASSO method, (which
we’ll cover next), that accomplish similar goals often more efficiently,
the <code>tidymodels</code> folks seem to <a
href="https://stackoverflow.com/questions/66651033/stepwise-algorithm-in-tidymodels#comment117845482_66651033">not
be interested in implementing subset selection anytime soon</a>.</p>
<p>Because of this, and since I don’t want to jump around different R
packages more than needed, we won’t actually practice subset selection.
But it’s an approach worth knowing about. While it is an approach that -
in my opinion - can be useful at times, you might want to consider other
methods at reducing overfitting first, e.g., the regularization approach
we discuss next.</p>
</div>
<div id="further-materials" class="section level1">
<h1>Further Materials</h1>
<p>For more details on subset selection, <a
href="https://statlearning.com/">see section 6.1. of ISLR</a> and <a
href="https://topepo.github.io/caret/">sections 18-22 of the caret
manual</a>.</p>
<p>As just mentioned, since <code>tidymodels</code> <a
href="https://stackoverflow.com/questions/66651033/stepwise-algorithm-in-tidymodels#comment117845482_66651033">currently
doesn’t support the subset selection approaches described here</a>, we
won’t try them. The next topic, regularization, does something similar
to subset selection and is often more computationally efficient. We will
try some of those methods.</p>
<p><a
href="https://projecteuclid.org/journals/statistical-science/volume-35/issue-4/Best-Subset-Forward-Stepwise-or-Lasso-Analysis-and-Recommendations-Based/10.1214/19-STS733.short">This
paper</a> by some rather famous statisticians discusses subset selection
and how it compares to methods like LASSO.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

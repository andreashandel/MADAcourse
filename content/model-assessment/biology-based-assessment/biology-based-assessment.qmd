---
title: "Biology based assessment"
#subtitle: "More info here if needed"
date: 2024-01-25
date-modified: last-modified
---

# Overview

This unit discusses the idea of assessing a model based on expert knowledge.


# Learning Objectives

* Be able to do X.


# Introduction

Subject-matter expertise is critical at every step of the modeling and analysis process. Your models need to make a-priori sense. For biomedical applications, the model needs to agree with known biology. More broadly speaking, the model needs to make sense, given what we know about reality. 

There are several aspects that you should keep in mind when assessing how overall reasonable a model is.


# Model choice

There are lots of different types of models available. 

You will have to make specific choices for your model. That is ok and part of the process of building models. Just ensure you always remember that results are contingent on the choices you made, and it is not clear how well they generalize. (Just another reminder that this is not unique to simulation models. If you do an experiment in a BALB/c mouse, it doesn’t mean the results would be the same in another type of mouse, let alone in humans). One way to figure out what impact the modeling choices have on outcomes is to explore a lot of different model variants. This quickly gets time-consuming and is rarely done. Occasionally, someone compares models of the same system done by different individuals/groups. A nice example is (Dobrovolny et al. 2013) in which the authors compared several influenza models. By comparing the models to each other and to data, they were able to discuss how models differed and which ones agreed with the data (spoiler alert: there was no one single best model, most of them were good at reproducing some data and not good at reproducing other data).



# Model complexity

Every model contains some abstraction/simplification of the real world. In addition to choosing an appropriate type of model, you also need to ensure it has the right level of detail.

There are no general rules dictating what simplifications are reasonable to make and which ones are not. It depends on the specifics of the system and the question. Even for the same system, different questions will lead to different models.

In [this paper](https://www.nature.com/articles/s41577-019-0235-3), we used maps as an analogy for determining the right amount and type of detail to put into a model[^1]. Maps are models of the real world. they serve specific purposes, and it is important that a given map be useful for the intended purpose. Consider the three maps (models) of the fictional country of antibodia (see the figure). If you want to know where this country is located, the left map is useful. if instead you want to know how to drive from t- town to Dendriticella, the middle map would be the most useful. if you want to know where most people live in this country, the right map is most useful. it is the same ‘system’ under consideration (the country of antibodia), but depending on the question, different maps (models) are needed. analogously, for the same biological system under study (for example, a specific pathogen and host), different types of models that include and exclude different details of the systems are needed, depending on the question you want to answer. The usefulness of maps (and models) is that they capture the information that is needed for a specific situation, while ignoring details that are not important for a given question, thus producing the right level of complexity.

[^1] I'm not the first one to come up with the map analogy. I'm not sure where I heard it first, but I know I didn't invent it. Only the specific example shown here is from our previous paper.

When you assess models, you need to ask yourself if you have the right level of detail to answer the question you are trying to answer.



# Summary

# Further Resources






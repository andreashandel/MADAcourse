---
title: Thinking about data generation
subtitle: ""
---


# Overview

We are generally in the business of analyzing data, not generating it (but see the _synthetic data_ content). Nevertheless, it is very important to think about the processes that generated the data you are trying to analyze.


# Learning Objectives

- Understand why it's important to think of the data generation process
- Be familiar with common features and structures in  data


# Introduction



# Data generation processes

Every dataset is generated by processes that can often be very complex. At times, seemingly similar data is generated by different processes. For instance, most of the text you read in this course was written by a single person. In contrast, a lot of the text you read in Wikipedia was co-authored and co-edited by many individuals. Thus, while both are pieces of text, the processes that generated them are different. Often, this difference in processes is reflected in patterns in the data, and needs to be accounted for.


## Randomness


## Measurements

## Interactions



# Data structures

Depending on the processes that generate the data, it is common for data to have certain structures. Thinking about those structures, and as suitable accounting for them in your analyses, is important. The following paragraphs describe a few important types of structure you likely encounter often. Of course, combinations of structures are always possible.



## Hierarchical data

This type of data is actually quite common. A hierarchy (also at times
called multi-level or nesting structure) occurs when there is some type
of grouping inherent. For instance, if you analyze heart attacks from
different hospitals, there might be systematic differences between
hospitals that are worth taking into account. You can then build models
that take that into account. I think there is a strong case to be made
that one should often start with a hierarchical modeling approach, and
only drop it if one is convinced that there are no systematic
differences in the data. Unfortunately, such hierarchical models are
still a little bit harder to implement, and often a lot harder to
understand and interpret. For such models, a Bayesian framework is often
very useful. A good introductory resource for hierarchical modeling, and
especially how to do it with `R`, is [*Statistical
Rethinking*](https://xcelab.net/rm/statistical-rethinking/) (the second
half of the book). The new edition of *R4DS* has a chapter on [working
with hierarchical data](https://r4ds.hadley.nz/rectangling.html) (but
does not cover the fitting/analysis part.) There is also a CRAN Task
view that lists [R packages relevant to hierarchical
modeling](https://cran.r-project.org/web/views/MixedModels.html).


## Time-series data

Time series are a specialized data type that are autocorrelated, and we
can therefore get better predictions by using specialized models that
take this data structure into account. A good resource is the free
textbook [*Forecasting: Principles and
Practice*](https://otexts.com/fpp3/) and a lot of the other work by [Rob
Hyndman](https://robjhyndman.com/).

A very useful set of tools to allow times-series work in R is the set of
packages called the [`tidyverts`](https://tidyverts.org/). The
[`modeltime`](https://business-science.github.io/modeltime/) `R` package
allows one to use the `tidymodels` framework to analyze time-series
data.

CRAN also has a [Task View for *Time Series
Analysis*.](https://cran.r-project.org/web/views/TimeSeries.html) (A
*Task View* on CRAN is a site that tries to combine and summarize
various R packages for a specific topic). Another task view that deals
with longitudinal/time-series data is the [*Survival Analysis* Task
View](https://cran.r-project.org/web/views/Survival.html).


## Spatial data

Like time series data, spatial data also feature autocorrelation, but
typically in two dimensions. (i.e., latitude and longitude.)
Spatiotemporal data, typically collected as repeated measurements of
spatial data over time, is also somewhat common. One could also have an
elevation coordinate and have 3D (or even 4D spatiotemporal data)
spatial data, but most analyses focus on 2D spatial autocorrelation
structures.

While there is (to my knowledge) no current way to fit specific spatial
models in `tidymodels` (i.e. no `modeltime` analogue), one can use
spatial resampling through the
[`spatialsample`](https://spatialsample.tidymodels.org/) package, which
provides resampling methods that take spatial autocorrelation into
account.

You can find a community-curated list of resources for spatial data in
[*The Big Book of R*](https://www.bigbookofr.com/geospatial.html) or in
the [*Spatial Data* CRAN task
view](https://cran.r-project.org/web/views/Spatial.html).


## Network data

At times, units of data you collect might be connected in a network. 



# Further resources
